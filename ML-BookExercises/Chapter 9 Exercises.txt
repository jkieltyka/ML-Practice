Question 1
The main benifits include:
- operations can be run in parallel or across different devices
- Tensorflow can automatically compute gradients for you

Main drawbacks:
- debugging can be harder
- it is harder to learn

Question 2
yes

Question 3
No, the first statement willl compute A and B using the defined graph in two runs while the second statement will do it in one run.
The results will be the same unless the calculation of one variable has side effects on the other calculation.

Question 4
No you can't you would need to merge the graphs to do this.

Question 5
They will use their own copies of the variable if using distributed tensor flow otherwise they will share the variable